import numpy as np
from random import random
from random import seed

#get data-------------------------------------
data = np.genfromtxt('winequality-red.csv', delimiter = ';') 
data = np.delete(data, 0,0) 

#print(data)

def mean_col(colonne,data):
	return np.mean(data.T[colonne])
def var_col(colonne,data):
	return np.var(data.T[colonne])

def preprocessing(ligne, col):
  y_ij = (float(data[ligne][col])-mean_col(col,data))/var_col(col,data) 
  #i = ligne, j = colonne
  return y_ij

for i in range(len(data.T[0])):
	for j in range(11): #range(len(data.T[0])
		data[i][j]= preprocessing(i,j) 

#print("data normalisé:", data[0])

training_set_inputs = np.delete(data, 11, 1)
training_set_outputs = (data.T[-1])/10
#print("inputs:", training_set_inputs[0])
#print("qualité du vin :", (training_set_outputs))


#1. Initialize Network-----------------------

class NeuralNetwork():
	def __init__(self,n_input,n_hidden,n_output):
		self.n_input = n_input
		self.n_hidden = n_hidden #pour cas général, n_hidden doit être une liste
		self.n_output = n_output
	#def initialize_network(self,n_input,n_hidden,n_output):
		#seed(1)
		self.weights = [] 
		h_layer = np.array([[random() for i in range(self.n_input+0)]for j in range(self.n_hidden)])#crée un weight par neurone de la couche hidden, +1 est le biais 
		o_layer = np.array([[random() for i in range(self.n_hidden+0)]for j in range(self.n_output)])  #même chose pour couche output
		self.weights.append(h_layer)
		self.weights.append(o_layer)
		
		#print(self.weights)
		

#2. Forward Propagate / obtenir un output ---------------
	#Fonction d'activation:
	def sigmoid(self,x):
		f = (1/(1+np.exp(-x)))
		return f

	#essayons de trouver un output:
	def output(self, neuron, wine , n_layer): #output général #n_hidden --> n_layer = 0 
		if n_layer == 0 : 
			out = np.dot(self.weights[n_layer][neuron], training_set_inputs[wine])
		else :
			out = np.dot(self.weights[n_layer][neuron], np.array([self.output( i ,wine , n_layer = n_layer -1) for i in range(self.n_hidden) ])) #range( n_hidden[n_layer] )
		return self.sigmoid(out)

	


#3.Backpropagating Errors-----------------------------------------
	def sigmoid_derivative(self,x):
		b = self.sigmoid(x) * (1 - self.sigmoid(x))
		return b


	def error_output(self, wine): 
		err_o = ( training_set_outputs[wine] - self.output(0,wine, 0)) * self.sigmoid_derivative(self.output(0, wine, 0))
		return err_o


	def error_hidden(self, neuron, wine, n_layer):
		#pour l'instant on a une seule couche hidden donc...
		w = self.weights[-1][0][neuron]
		e = self.error_output(wine) 
		out_m = self.output(neuron, wine, n_layer)
		err_h = (w*e)*self.sigmoid_derivative(out_m)
		return err_h
		
	#on va backpropagate et stocker nos valeurs
	def array_errors(self):
		err_o = np.array([self.error_output(k) for k in range(5)])    #len(data))])
		err_h = np.array([[self.error_hidden(i, j, 0) for i in range(self.n_hidden)] for j in range(5)])  #len(data))])
		return [err_h, err_o]
		
		
#4. Update weights -----------------------------------
	

	def update_weights(self, wine, l_rate): #Poids couche interne
		true = training_set_outputs[wine]
		for k in range(len(self.weights[0])):
		  for i in range(11):
		    self.weights[0][k][i] = self.weights[0][k][i] + l_rate * self.error_hidden(k, wine,0) * float(training_set_inputs[wine][i])
		#print(slef.error_hidden(self,k,ligne)) #Ne print que 0.0
		#Poids couche externe:
		for j in range(len(self.weights[0])):
		  self.weights[1][0][j] = self.weights[1][0][j] + l_rate * self.error_output(wine) * self.output(j, wine ,0)
		  
		  
	def train(self,l_rate, n_epoch):
		for i in range(len(data)):
		  for epoch in range(n_epoch):
		    liste = [self.output(k,i,0) for k in range(self.n_hidden)]
		    a = self.output(0,i,1)
		    self.error_output(i)
		    for d in range (self.n_hidden):
		    	self.error_hidden(d,i,0)
		    self.update_weights(i,l_rate)	
		    
#Tester notre code -------------------------------
NN = NeuralNetwork(11,3,1)
"""
print("output:", NN.output(2,5,0))
print("output error:",NN.error_output(5))
print("hidden error:" ,NN.error_hidden(2, 5, 0))

#print([.error_output(k) for k in range(len(data))])

print("maybe mistaken errors:", NN.array_errors() )
	
#print(len(data))

NN.update_weights( 5, 0.5)
print(NN.weights)


print("original:",NN.weights)
NN.update_weights( 5, 0.8)
print("updated:",NN.weights)
"""
#NN.train(0.8, 100)
#print("after training",NN.weights)
